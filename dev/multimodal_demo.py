# multimodal_demo.py - Complete multimodal dashboard demonstration

import requests
import os
import time

def create_test_files():
    """Create test audio and video files for demonstration"""
    
    # Create mock audio file (WAV format)
    with open('demo_audio.wav', 'wb') as f:
        # WAV header + some data
        f.write(b'RIFF')
        f.write((1000).to_bytes(4, 'little'))  # File size
        f.write(b'WAVE')
        f.write(b'fmt ')
        f.write((16).to_bytes(4, 'little'))   # Format chunk size
        f.write(b'\x01\x00\x01\x00')         # Audio format and channels
        f.write((44100).to_bytes(4, 'little')) # Sample rate
        f.write(b'\x00' * 100)               # Audio data
    
    # Create mock video file (MP4-like)
    with open('demo_video.mp4', 'wb') as f:
        # MP4 header + some data
        f.write(b'\x00\x00\x00\x20ftypmp42')
        f.write(b'\x00' * 500)  # Video data
    
    print("âœ… Created test files: demo_audio.wav, demo_video.mp4")

def test_multimodal_dashboard():
    base_url = "http://localhost:8003"
    
    print("ğŸ­ COMPLETE MULTIMODAL DASHBOARD DEMONSTRATION")
    print("=" * 70)
    
    # Check server health
    print("\nğŸ” STEP 1: Server Health Check")
    try:
        response = requests.get(f"{base_url}/health")
        print(f"âœ… Server Status: {response.json()}")
    except Exception as e:
        print(f"âŒ Server Error: {e}")
        return
    
    print(f"\nğŸŒ STEP 2: Dashboard URLs")
    print(f"ğŸ“Š Enhanced Dashboard: {base_url}/dashboard")
    print(f"ğŸ“š API Documentation: {base_url}/docs")
    
    # Test Text Analysis
    print(f"\nğŸ“ STEP 3: Text Sentiment Analysis")
    print("-" * 50)
    text_tests = [
        "I absolutely love this amazing product!",
        "This is terrible and disappointing!",
        "The weather is okay today."
    ]
    
    for text in text_tests:
        try:
            response = requests.post(f"{base_url}/predict/text", 
                                   json={"text": text})
            result = response.json()
            emoji = "ğŸ˜Š" if result['sentiment'] == 'positive' else "ğŸ˜" if result['sentiment'] == 'negative' else "ğŸ˜"
            print(f"{emoji} \"{text}\" â†’ {result['sentiment'].upper()} ({result['confidence']:.1%})")
        except Exception as e:
            print(f"âŒ Text test failed: {e}")
    
    # Create test files
    print(f"\nğŸ“ STEP 4: Creating Test Media Files")
    create_test_files()
    
    # Test Audio Analysis
    print(f"\nğŸµ STEP 5: Audio Sentiment Analysis")
    print("-" * 50)
    try:
        with open('demo_audio.wav', 'rb') as f:
            files = {'file': ('demo_audio.wav', f, 'audio/wav')}
            response = requests.post(f"{base_url}/predict/audio", files=files)
            result = response.json()
            emoji = "ğŸ˜Š" if result['sentiment'] == 'positive' else "ğŸ˜" if result['sentiment'] == 'negative' else "ğŸ˜"
            print(f"{emoji} Audio Analysis â†’ {result['sentiment'].upper()} ({result['confidence']:.1%})")
            print(f"   ğŸ“ File Size: {result['file_size']} bytes")
            print(f"   â±ï¸  Processing Time: {result['processing_time']}s")
    except Exception as e:
        print(f"âŒ Audio test failed: {e}")
    
    # Test Video Analysis
    print(f"\nğŸ¥ STEP 6: Video Sentiment Analysis")
    print("-" * 50)
    try:
        with open('demo_video.mp4', 'rb') as f:
            files = {'file': ('demo_video.mp4', f, 'video/mp4')}
            response = requests.post(f"{base_url}/predict/video", files=files)
            result = response.json()
            emoji = "ğŸ˜Š" if result['sentiment'] == 'positive' else "ğŸ˜" if result['sentiment'] == 'negative' else "ğŸ˜"
            print(f"{emoji} Video Analysis â†’ {result['sentiment'].upper()} ({result['confidence']:.1%})")
            print(f"   ğŸ“ File Size: {result['file_size']} bytes")
            print(f"   â±ï¸  Processing Time: {result['processing_time']}s")
    except Exception as e:
        print(f"âŒ Video test failed: {e}")
    
    # Test Multimodal Analysis
    print(f"\nğŸ­ STEP 7: Multimodal Fusion Analysis")
    print("-" * 50)
    try:
        with open('demo_video.mp4', 'rb') as f:
            files = {'file': ('demo_video.mp4', f, 'video/mp4')}
            response = requests.post(f"{base_url}/predict/multimodal", files=files)
            result = response.json()
            
            emoji = "ğŸ˜Š" if result['fused_sentiment'] == 'positive' else "ğŸ˜" if result['fused_sentiment'] == 'negative' else "ğŸ˜"
            print(f"{emoji} Fused Result â†’ {result['fused_sentiment'].upper()} ({result['confidence']:.1%})")
            print(f"   â±ï¸  Total Processing: {result['processing_time']}s")
            
            print(f"   ğŸ“Š Individual Modality Results:")
            for individual in result['individual']:
                ind_emoji = "ğŸ˜Š" if individual['sentiment'] == 'positive' else "ğŸ˜" if individual['sentiment'] == 'negative' else "ğŸ˜"
                print(f"      {ind_emoji} {individual['modality'].title()}: {individual['sentiment']} ({individual['confidence']:.1%})")
                
    except Exception as e:
        print(f"âŒ Multimodal test failed: {e}")
    
    # Dashboard Features Summary
    print(f"\nğŸ¯ STEP 8: Enhanced Dashboard Features")
    print("-" * 50)
    print("âœ… Text Analysis - Real-time sentiment from text input")
    print("âœ… Audio Upload - Drag & drop .wav, .mp3, .m4a files")
    print("âœ… Video Upload - Drag & drop .mp4, .avi, .mov files")
    print("âœ… Multimodal Fusion - Combined analysis from multiple sources")
    print("âœ… Mode Selection - Easy switching between analysis types")
    print("âœ… File Type Validation - Automatic file format detection")
    print("âœ… Progress Visualization - Animated confidence bars")
    print("âœ… Individual Results - Breakdown of multimodal analysis")
    print("âœ… Professional UI - Modern, responsive design")
    print("âœ… Quick Test Examples - One-click sentiment testing")
    
    # Usage Instructions
    print(f"\nğŸš€ STEP 9: How to Use the Enhanced Dashboard")
    print("-" * 50)
    print("1. ğŸŒ Open browser â†’ http://localhost:8003/dashboard")
    print("2. ğŸ“ For Text: Select 'Text' mode, enter text, click Analyze")
    print("3. ğŸµ For Audio: Select 'Audio' mode, upload .wav/.mp3 file")
    print("4. ğŸ¥ For Video: Select 'Video' mode, upload .mp4/.avi file")
    print("5. ğŸ­ For Multimodal: Select 'Multi' mode, upload media file")
    print("6. ğŸ“Š View results with confidence scores and progress bars")
    print("7. ğŸ”„ Try different files and modes to test all features")
    
    # Clean up test files
    print(f"\nğŸ§¹ STEP 10: Cleanup")
    try:
        os.remove('demo_audio.wav')
        os.remove('demo_video.mp4')
        print("âœ… Cleaned up test files")
    except:
        print("âš ï¸  Some test files may still exist")
    
    print(f"\nğŸ‰ MULTIMODAL DASHBOARD DEMONSTRATION COMPLETE!")
    print("=" * 70)
    print(f"ğŸŒ Your enhanced dashboard is live at: {base_url}/dashboard")
    print("ğŸ­ Ready for complete multimodal sentiment analysis!")

if __name__ == "__main__":
    test_multimodal_dashboard()
