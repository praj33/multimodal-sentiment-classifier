<div align="center">

# ğŸ­ **Advanced Multimodal Sentiment Analysis**

### *Enterprise-Grade AI Platform for Text, Audio & Video Sentiment Analysis*

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

**ğŸš€ Production-ready multimodal sentiment analysis with advanced AI fusion, real-time processing, and comprehensive deployment options.**

[ğŸ **Quick Start**](#-quick-start) â€¢ [ğŸ“š **API Docs**](#-api-reference) â€¢ [ğŸŒ **Dashboard**](#-web-dashboard) â€¢ [ğŸ‘¥ **Team Integration**](#-team-integration) â€¢ [ğŸ³ **Deploy**](#-deployment)

---

</div>

## âœ¨ **Key Features**

### ğŸ§  **Advanced AI Models**
- **ğŸ“ Text Analysis**: BERT-based with 27+ emotion detection
- **ğŸµ Audio Analysis**: MFCC + spectral features with ML classification  
- **ğŸ¥ Video Analysis**: MediaPipe facial expression recognition
- **ğŸ­ Fusion Engine**: Confidence-weighted multimodal integration

### âš¡ **Performance & Scalability**
- **Real-time Processing**: Sub-second response times
- **Batch Processing**: Efficient multi-input handling
- **Streaming Support**: WebSocket and SSE capabilities
- **GPU Acceleration**: CUDA-optimized inference

### ğŸ›¡ï¸ **Enterprise Security**
- **Input Validation**: 50MB file limits, type checking
- **XSS Protection**: Content sanitization
- **Rate Limiting**: DDoS protection
- **Security Headers**: OWASP compliance

### ğŸ¯ **Production Ready**
- **Docker Deployment**: Multi-stage builds with GPU/CPU support
- **Load Balancing**: Nginx configuration included
- **Monitoring**: Health checks, metrics, logging
- **Auto-scaling**: Kubernetes HPA/VPA ready

## ğŸ **Quick Start**

### Prerequisites
- **Python**: 3.8+ (3.10+ recommended)
- **Memory**: 4GB+ RAM (8GB+ for GPU)
- **Storage**: 2GB+ free space

### 1ï¸âƒ£ **Installation**

```bash
# Clone repository
git clone https://github.com/praj33/multimodal_sentiment.git
cd multimodal_sentiment

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ **Quick Test**

```bash
# Test classifiers
python test_audio_video.py

# Start server
python start_server.py

# Open dashboard
# http://localhost:8000/dashboard
```

### 3ï¸âƒ£ **Docker Deployment**

```bash
# CPU deployment
docker-compose up --build

# GPU deployment (NVIDIA Docker required)
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up --build
```

## ğŸ”§ **API Reference**

### **Text Analysis**
```bash
curl -X POST "http://localhost:8000/predict/text" \
     -H "Content-Type: application/json" \
     -d '{"text": "I absolutely love this amazing product!"}'
```

**Response:**
```json
{
  "sentiment": "positive",
  "confidence": 0.987,
  "model_version": {"text": "v2.0"},
  "emotions": {
    "joy": 0.85,
    "excitement": 0.72,
    "satisfaction": 0.68
  },
  "processing_time": 45.2
}
```

### **Audio Analysis**
```bash
curl -X POST "http://localhost:8000/predict/audio" \
     -F "file=@test_files/audio/positive_happy_tone.wav"
```

### **Video Analysis**
```bash
curl -X POST "http://localhost:8000/predict/video" \
     -F "file=@test_files/video/positive_bright_video.mp4"
```

### **Multimodal Fusion**
```bash
curl -X POST "http://localhost:8000/predict/multimodal" \
     -F "text=Great experience!" \
     -F "audio_file=@audio.wav" \
     -F "video_file=@video.mp4"
```

### **Batch Processing**
```bash
curl -X POST "http://localhost:8000/predict/batch" \
     -F "texts=Happy day" \
     -F "texts=Sad news" \
     -F "files=@audio1.wav" \
     -F "files=@video1.mp4"
```

## ğŸŒ **Web Dashboard**

Access the interactive dashboard at `http://localhost:8000/dashboard`

**Features:**
- **ğŸ“¤ File Upload**: Drag & drop audio/video files
- **ğŸ“ Text Input**: Real-time text analysis
- **ğŸ“Š Visualizations**: Confidence scores and emotion breakdowns
- **ğŸ›ï¸ Controls**: Adjust fusion weights in real-time
- **ğŸ“ˆ Analytics**: Performance metrics and history

## ğŸ‘¥ **Team Integration**

### **Avatar Emotions (Gandhar)**
```yaml
# config/fusion_config.yaml
team_presets:
  gandhar_avatar_emotions:
    video_weight: 0.6
    audio_weight: 0.3
    text_weight: 0.1
```

### **AI Teacher Scoring (Vedant/Rishabh)**
```yaml
team_presets:
  vedant_ai_teacher:
    text_weight: 0.7
    audio_weight: 0.2
    video_weight: 0.1
```

### **Content Moderation (Shashank)**
```yaml
team_presets:
  shashank_content_mod:
    text_weight: 0.5
    audio_weight: 0.3
    video_weight: 0.2
    confidence_threshold: 0.8
```

## âš™ï¸ **Configuration**

### **Fusion Weights** (`config/fusion_config.yaml`)
```yaml
fusion_algorithms:
  confidence_weighted:
    text_weight: 0.5
    audio_weight: 0.3
    video_weight: 0.2
    
hot_reload:
  enabled: true
  check_interval: 30
```

### **Model Configuration** (`config/model_config.yaml`)
```yaml
models:
  text:
    model_name: "cardiffnlp/twitter-roberta-base-sentiment-latest"
    device: "auto"
    batch_size: 32
```

## ğŸ³ **Deployment**

### **Development**
```bash
docker-compose up --build
```

### **Production with GPU**
```bash
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
```

### **Kubernetes**
```bash
kubectl apply -f k8s/
```

### **Environment Variables**
```bash
# .env file
MODEL_CACHE_DIR=/app/models
LOG_LEVEL=INFO
ENABLE_GPU=true
MAX_WORKERS=4
```

## ğŸ§ª **Testing**

### **Unit Tests**
```bash
python -m pytest tests/ -v
```

### **Integration Tests**
```bash
python test_files/test_classifiers.py
```

### **Load Testing**
```bash
python tests/load_test.py
```

### **Test Files**
The repository includes comprehensive test files:
- **Audio**: 6 WAV files with different sentiment characteristics
- **Video**: 5 MP4 files with varying visual patterns
- **Automated Testing**: Complete test suite for all classifiers

## ğŸ“ˆ **Performance Benchmarks**

| Model Type | Avg Latency | Throughput | Memory Usage |
|------------|-------------|------------|--------------|
| Text       | 45ms        | 2000 req/s | 1.2GB        |
| Audio      | 120ms       | 800 req/s  | 800MB        |
| Video      | 250ms       | 400 req/s  | 2.1GB        |
| Multimodal | 180ms       | 500 req/s  | 2.8GB        |

## ğŸ“š **Documentation**

- **[API Reference](docs/API_REFERENCE.md)** - Complete API documentation
- **[Fusion Guide](docs/FUSION_CONFIGURATION_GUIDE.md)** - Advanced fusion configuration
- **[SDK Documentation](docs/SDK_DOCUMENTATION.md)** - Python SDK usage
- **[Deployment Guide](docs/DEPLOYMENT.md)** - Production deployment

## ğŸ› ï¸ **Development**

### **Code Quality**
```bash
# Format code
black .
isort .

# Lint code  
flake8 .
pylint src/

# Type checking
mypy .
```

### **Pre-commit Hooks**
```bash
pre-commit install
pre-commit run --all-files
```

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **Hugging Face** for transformer models
- **MediaPipe** for video analysis
- **FastAPI** for the web framework
- **Docker** for containerization

---

<div align="center">

**Built with â¤ï¸ by praj33**

[ğŸŒŸ Star this repo](https://github.com/praj33/multimodal_sentiment) â€¢ [ğŸ› Report Bug](https://github.com/praj33/multimodal_sentiment/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/praj33/multimodal_sentiment/issues)

</div>
